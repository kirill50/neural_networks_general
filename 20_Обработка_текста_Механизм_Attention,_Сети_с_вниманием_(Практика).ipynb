{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CisjvJh3bdIw"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1f2RV3yzZIqRoGpP9y-b45NgnivaIT-4q?usp=sharing)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XhodKqwLjQ6"
      },
      "source": [
        "Разберем обучение более подробно на примере готовой сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LxGv5bdgmN"
      },
      "source": [
        "# модуль для загрузки файлов в colab\n",
        "from google.colab import files \n",
        "\n",
        "# Подключим tensorflow\n",
        "import tensorflow as tf \n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Используем метод для формирования последовательностей одинаковой длины\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "\n",
        "# Загружаем абстрактный класс базовой модели сети от кераса\n",
        "from tensorflow.keras.models import Model \n",
        "\n",
        "# Подключим необходимые слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
        "\n",
        "# Подключим оптимайзер\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "# Подключим функцию потерь\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Подключим numpy - библиотеку для работы с массивами данных\n",
        "import numpy as np \n",
        "\n",
        "# Подключим библиотеку для визуализации данных\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Подключим модуль для определения форматирования и местоположения делений на осях графиков\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "# Подключим модуль для разбивки данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Подключим модуль для работы с регулярными выражениями\n",
        "import re \n",
        "\n",
        "# Подключим модуль для работы с временем\n",
        "import time\n",
        "\n",
        "# Подключим модуль для работы с операционной системой\n",
        "import os \n",
        "\n",
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IjqYknxCqmX8",
        "outputId": "f33aeaa6-f567-40d9-d733-ffacd2ffc1dc"
      },
      "source": [
        "# Скачаем датасетa из пар фраз на русском и английском языках \n",
        "\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/advanced/l3/rus-eng.zip', None, quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rus-eng.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGGoRhuVyd_W"
      },
      "source": [
        "Распакуем скачанные тексты и убедимся в появлении файла со словарем:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VlOfx4jtB9e",
        "outputId": "2e82be78-bec7-4810-e296-02c515860238"
      },
      "source": [
        "!unzip -o rus-eng.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHBPiDxa9_Mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbef915b-b476-49b7-fac6-e52724e906bd"
      },
      "source": [
        "# Проверим распакованные файлы\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  rus-eng.zip  rus.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7TDn54-ATt"
      },
      "source": [
        "# Определим переменную с именем файла с датасетом\n",
        "path_to_file=\"rus.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGAVJe9iynJi"
      },
      "source": [
        "Определим функцию для подготовки предложений из словаря для обучения нейронной  сети. Добавим пробелы между словами и знаками препинаний, служебные символы заменим на пробелы, уберем пробелы в начале и конце фразы., добавим тег `< start >` в начало фразы, `< end >` в конец:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWA1mr0Rqq_9"
      },
      "source": [
        "def preprocess_sentence(phrases): # Функция принимает содержимое словаря\n",
        "\n",
        "  # Разделяем пробелами слова и знаки препинания(\"А как насчет тебя? \" -> \"А как насчет тебя ? \") \n",
        "  phrases = re.sub(r\"([?.!,;:])\", r\" \\1 \", phrases) # r\" \\1 \" берёт значения 1й группы в скобках; обрамляем указанные символы пробелами\n",
        "\n",
        "  # Заменяем всё на пробелы, за исключением (a-zA-Zа-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:]+\", \" \", phrases) \n",
        "  \n",
        "  # Получаем строку без случайных лишних пробелов в конце фраз(rstrip удаляет с конца строки)\n",
        "  phrases = phrases.rstrip().strip()      \n",
        "\n",
        "  # Для нашей модели обозначим тегами начало и конец предложения  \n",
        "  phrases = '<start> ' + phrases + ' <end>' \n",
        "\n",
        "  # Функция возвращает предобработанные фразы\n",
        "  return phrases "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKj6v9AIvdSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58a8aab-d6cc-4a8f-9b90-8cf6f0c22164"
      },
      "source": [
        "# Покажем пример обработки фразц\n",
        "\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид:\") \n",
        "print(preprocess_sentence(\"What about you?\"))                         # Выведем пример до обработки \n",
        "print(preprocess_sentence(\"А как насчет тебя?\"))                      # И после"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид:\n",
            "<start> What about you ? <end>\n",
            "<start> А как насчет тебя ? <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWrBY276Oyb-"
      },
      "source": [
        "Перегоним фразы в датасет. Он представляет список пар из русского и английского предложения. Будем использовать только первые num_examples пар"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5zJhQmqvyNC"
      },
      "source": [
        "Создадим функцию по формированию датасета. На вход принимает путь к файлу с датасетом и требуемый размер датасета. Читает файл построчно и на выходе формирует список пар фраз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRaVcSowqr9e"
      },
      "source": [
        "# Функция создания датасета\n",
        "\n",
        "def create_dataset(path,          # Путь к файлу\n",
        "                   num_examples): # Необходимый размер датасета \n",
        "\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')[0:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  # Вернем пары фраз в виде [по-английски, по-русски]\n",
        "  return zip(*word_pairs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5iuvrauv4KN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcd5787-8102-44e7-e70f-3f57a616e8cd"
      },
      "source": [
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "\n",
        "english, russian = create_dataset(path_to_file,40000) # Вызовем функцию для демонстрации\n",
        "print(english[-1])                                    # Выведем последний элемент из списка английских фраз\n",
        "print(russian[-1])                                    # Выведем последний элемент из списка русских фраз"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> Don t be too long . <end>\n",
            "<start> Не тяните . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOf8RMSPSz-"
      },
      "source": [
        "Создадим функцию для получения максимальной длины фразы из списка. На вход принимает список фраз. Перебирает список, выбираем максимальное значение длины"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xw1cPZqu5d"
      },
      "source": [
        "# Создадим мини-функцию, возвращающую максимальную длину тензора\n",
        "def max_length(tensor): # Функция принимает на вход тензор(фразы в виде последовательности индексов)\n",
        "\n",
        "  # Вернем значение максимальной длины его элемента \n",
        "  return max(len(t) for t in tensor) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg-GwLJoPtyJ"
      },
      "source": [
        "Функция преобразовывает тексты в последовательности индексов. \n",
        "Используем стандартный токенайзер из модуля Keras. На вход принимает текст, обучает на нем токенайзер. Переводит текст в токены. Отдает полученые токены и токенайзер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTLSJIakPmEz"
      },
      "source": [
        "def tokenize(language): # Функция принимает текст одного из языков\n",
        "\n",
        "  language_tokenizer = Tokenizer(filters='')               # Вызываем класс Токенизатор, просим его не удалять символы, которые он удаляет по умолчанию\n",
        "  language_tokenizer.fit_on_texts(language)                # \"скармливаем\" ему тексты для обработки и сборки словаря частотности\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) # Разбиваем текст фраз на последовательности индексов\n",
        "  tensor = pad_sequences(tensor, padding='post')           # Делаем последовательности фиксированной длины, заполняя нулями более короткие фразы\n",
        "\n",
        "  # Возвращаем последовательность индексов(назовем ее тензор) и токенизатор\n",
        "  return tensor, language_tokenizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNNJMfvQBP6"
      },
      "source": [
        "Функция формирующая готовый датасет. Получает на вход путь к файлу с текстами и необходимый размер готового датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaKt_YpuPmbQ"
      },
      "source": [
        "def load_dataset(path,               # Путь к файлу с текстами\n",
        "                 num_examples=None): # Необходимый объем датасета\n",
        "\n",
        "    # Из исходного текста делаем датасет пар фраз, причём входным языком для сети сделаем русский\n",
        "    targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "    # Разбиваем текст на последовательность индексов(назовем ее тензор)\n",
        "    input_tensor, inp_language_tokenizer = tokenize(inp_language)    # Формируем тензоры и токенизатор для русского языка\n",
        "    target_tensor, targ_language_tokenizer = tokenize(targ_language) # Формируем тензоры и токенизатор для английского языка\n",
        "\n",
        "    # Функция вернёт: тензор для русского языка, для английского языка; токенизаторы для русского и английского языков\n",
        "    return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqAYnjBzQMeO"
      },
      "source": [
        "Формируем датасет заданного объема - 40000 (в зависимости от приоритета скорости либо качества обучения), используем ранее написанные функции:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfw_d52qxtK"
      },
      "source": [
        "num_examples = 40000 # Выберем 40 тысяч строк(всего в базе около 360тысяч строк, в каждой пара фраз)\n",
        "\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UCqJHiw5ikC"
      },
      "source": [
        "Создадим вспомогательную функцию для вывода слова фразы и его индекса. На вход подаются токенайзер и фраза:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Xhk8pb5byY"
      },
      "source": [
        "# Визуализируем собранные данные\n",
        "\n",
        "def convert(language_tokenizer,  # Токенайзер\n",
        "            tensor):             # Список индексов слов\n",
        "            \n",
        "  #  Цикл по токенам во фразе\n",
        "  for t in tensor:  \n",
        "    if t!=0:                                                        # Если токен не 0. Т.е. не мусор в конце фразы\n",
        "      print (\"%d ----> %s\" % (t, language_tokenizer.index_word[t])) # Выводи токен и соответствующее слово\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6tkpocE6X_3"
      },
      "source": [
        "Посмотрим на примеры\n",
        "В первом блоке выведем русскую фразу и ее токен\n",
        "Во втором агнлийскую.\n",
        "\n",
        "Далее выводим статистику по датасету"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XeriQf5fVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc086f6-8c07-413d-d393-23066420f346"
      },
      "source": [
        "print (\"Фраза на русском языке; соответствие индекса и слова\")   \n",
        "convert(inp_language_tokenizer, input_tensor_train[0])           # Выведем нулевую пару из русского датасета\n",
        "print ()    \n",
        "\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])         # Выведем нулевую пару из агнлийского датасета\n",
        "print ()   \n",
        "                                                      \n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")# Выведем статистику по обучающей выборке\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")               # Выведем статистику по тестовой выборке"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "9 ----> ты\n",
            "740 ----> посмотрел\n",
            "22 ----> на\n",
            "14 ----> меня\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "6 ----> you\n",
            "291 ----> looked\n",
            "75 ----> at\n",
            "16 ----> me\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3AgPtOj83H9"
      },
      "source": [
        "Создаем `tf.data` датасет (Раздел `tf.data.Dataset API` предлагает построить готовый конвейер для обучения моделей)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEJJsHy9rp5"
      },
      "source": [
        "# Определим постоянные \n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)                     # Укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "BATCH_SIZE = 256                                          # Указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE     # Укажем количество шагов в одной эпохе\n",
        "embedding_dim = 256                                       # Размерность эмбеддинга, векторного пространства\n",
        "units = 1024                                              # Задаем размер слоя(количество нейронов в слое) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB82awfvDB6o"
      },
      "source": [
        "# Задаем размер русского словаря\n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Задаем размер английского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 \n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDgb_Z7y98ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da4bba3-e5d5-438e-eb20-3e8f8c6b5f30"
      },
      "source": [
        "# Посмотрим на форму примеров полученных батчей\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([256, 12]), TensorShape([256, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZE7WSCKQ4-H"
      },
      "source": [
        "Вспомним нашу схему - сеть состоит их кодера, декодера и блока attention.\n",
        "\n",
        "Давайте начнем оформлять кодер в виде класса. В этом примере кодер состоит из блоков `Embedding` и `GRU`. Обратим внимание на `return_sequences=True`, `return_state=True` - мы требуем состояния кодера на каждом шаге работы. \n",
        "\n",
        "На вход принимает фразу для перевода и начальное состояние. Отдает выход GRU и вектор скрытых состояний"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwqiGRCDCu1"
      },
      "source": [
        "class Encoder(Model):\n",
        "\n",
        "  # Конструктор класса \n",
        "  def __init__(self, \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размер пространсва эмбеддинга\n",
        "               enc_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "\n",
        "    super(Encoder, self).__init__()                                   # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                                          # Атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units                                        # Атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)             # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=256\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, \n",
        "           x,       # Входная фраза\n",
        "           hidden): # Начальное энкодера\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "\n",
        "    # Выход сети GRU и состояние на выходе\n",
        "    return output, state \n",
        "\n",
        "  # Создаем метод инициализации состояний на скрытых слоях\n",
        "  def initialize_hidden_state(self):\n",
        "\n",
        "    # Вернем тензор из нулей размер батча на размер слоя, итсполбьзуем как начальное состояние энкодера\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BoTUmLPSsha"
      },
      "source": [
        "Создаем экземпляр класса Encoder. Используем далее как готовый модуль при построении модели сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgR4bQIKDFXF"
      },
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXH74Z-B_Mmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bdf589e-f497-4c04-f51c-557594d4e76b"
      },
      "source": [
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (256, 12, 1024)\n",
            "Размеры скрытого состояния: (batch size, units) (256, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKRwq1d-S86R"
      },
      "source": [
        "Создадим класс модуля `attenton`, как предписывал Bahdanau. Разбор работы данного модуля мы прошли чуть ранее. На входе состояния кодера `hidden_state` и `values` - выход предыдущего декодера с предыдущего шага. На выходе вектор контекста и веса `attention`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWDTK8eqDHu0"
      },
      "source": [
        "class BahdanauAttention(Model): # Название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "\n",
        "  # Создаем конструктор класса\n",
        "  def __init__(self, \n",
        "               units):                        # Число нейронов \n",
        "\n",
        "    super(BahdanauAttention, self).__init__() # Даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.W2 = Dense(units)                    # Создаем Dense с заданным числом нейронов\n",
        "    self.V =  Dense(1)                        # Создаем Dense с числом нейронов =1\n",
        "\n",
        "  # Метод принимает состояние и выход энкодера ----------------------------------\n",
        "  \n",
        "  def call(self, \n",
        "           hidden_state, # Состояние энкодера\n",
        "           values):      # Выход энкодера\n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # Веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # Размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    # Возвращает вектор контекста и веса внимания\n",
        "    return context_vector, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8sMHv-wU_oD"
      },
      "source": [
        "Создадим экземпляр класса BahdanauAttention. Здесь 10 - число нейронов в первом dense слое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUv-DSsDDKGl",
        "outputId": "f190cd71-578c-4ffe-8d52-0877d2bec5cb"
      },
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (256, 1024)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (256, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK4api1fVM3N"
      },
      "source": [
        "Создаем класс декодера с attention. Декодер принимает обущающую фразу, прогоняет через embedding. Далее склеивает с вектором контента и подает на GRU.\n",
        "На выходе dense слой с числом нейронов равному размеру словаря."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZHTEgDoDNBC"
      },
      "source": [
        "class Decoder(Model):\n",
        "\n",
        "  # Создадим конструктор класса\n",
        "  def __init__(self,   \n",
        "               vocab_size,    # Размер словаря\n",
        "               embedding_dim, # Размерность пространства эмбеддинга\n",
        "               dec_units,     # Число нейронов в GRU\n",
        "               batch_sz):     # Размер батча\n",
        "    super(Decoder, self).__init__()                       # Даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz                              # Атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units                            # Атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) # Атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    self.fc = Dense(vocab_size) # Атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "\n",
        "  def call(self, \n",
        "           x,           # Начальный токен\n",
        "           hidden,      # Состояние  энкодера\n",
        "           enc_output): # Выход энкодера\n",
        "\n",
        "    # Enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # Входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # Дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # Сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # Output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # Пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    # Вернем выходную фразу, вектор состояния, веса внимания\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1yEPu3DPqp",
        "outputId": "a547812c-18ae-4c7f-cad8-cc3179932a25"
      },
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((256, 1)), sample_hidden, sample_output)\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (256, 4271)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h7uiC6LDVRK"
      },
      "source": [
        "# Выбираем оптимайзер Adam\n",
        "optimizer = Adam() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qw4cgWJlDgW"
      },
      "source": [
        "Наша функция потерь называется  `loss_function` - сначала она уберет из расчетов нулевые элементы в истинной и предсказанной фразе. \n",
        "\n",
        "Длина фразы может быть меньше максимально допустимой или фраза может быть сформирована не полностью. Просто не будем учитывать мусор в конце фразы.\n",
        "\n",
        "Далее применим стандартную для Kerasa функцию потерь  SparseCategoricalCrossentropy. По сравнению CategoricalCrossentropy работает также, но позволяет нам не хранить слова в виде OneHotEncoding, что существенно экономить память.\n",
        "\n",
        "На выходе получаем среднее значение потерь:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YVxy08qDR-5"
      },
      "source": [
        "# Используем SparseCategoricalCrossentropy, к-я может работать с некатегориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') # Выбираем функцию потерь\n",
        "\n",
        "def loss_function(real, pred):                       # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) # Найдем маску, которая уберет нулевые значения индексов в конце фразы\n",
        "  loss_ = loss_object(real, pred)                    # Фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)            # Согласуем тип маски с типом потерь\n",
        "  loss_ *= mask                                      # Накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  \n",
        "  # Вернем reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHr21E05q0NN"
      },
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'                                               # Даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")                                # Добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) # Сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFb7r1SjYf7i"
      },
      "source": [
        "Создадим функцию для обучения модели. На входе - исходная фраза, конечная фраза, начальное состояния кодера. Подаем сразу батчем. На выходе потери на этом батче"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCNvA66Jq7nE"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp,         # Входная фраза\n",
        "               targ,        # Точный перевод\n",
        "               enc_hidden): # Состояния энкодера\n",
        "\n",
        "  # Создаем переменную, в которую будем записывать ошибку\n",
        "  loss = 0                             \n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # Передадим это состояние декодеру\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "  batch_loss = (loss / int(targ.shape[1])) \n",
        "\n",
        "  # Создаем список переменных, для которых TensorFlow будет вычислять градиенты\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  # Отслеживаем градиент\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Корректируем веса\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Функция обучения вернет ошибку на батче\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwOr3sEYiW_"
      },
      "source": [
        "Обучаем сеть. 30 эпох. На каждой эпохе прогоняем весь набор данных через функцию обучения. Считаем лоссы. Сохраняем статистику каждые 10 эпох"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Tpy6Cxq-V3",
        "outputId": "2080072d-6b30-4db4-8cb3-0b836a176b3c"
      },
      "source": [
        "EPOCHS = 30 # устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): # Цикл по каждой эпохе\n",
        "  start = time.time() # Запомним время начала эпохи\n",
        "\n",
        "  progbar = tf.keras.utils.Progbar(target=steps_per_epoch, stateful_metrics=[\n",
        "                                     'batch_loss'], unit_name='batch')        # Создадим индикатор прогресс обучения\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() # Задаем начальное состояние на скрытом слое encodera \n",
        "  total_loss = 0                                 # Начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) # Передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss                       # Добавим ее в итоговую ошибку\n",
        "    progbar.update(                                # Обновим состояние индикатора обучения\n",
        "            batch + 1, values=[('batch_loss', batch_loss)])\n",
        "\n",
        "\n",
        "  # Каждые 10 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch)) # Выведем номер эпохи и потери\n",
        "  print('Время на 1 эпоху {} сек'.format(round(time.time() - start), 1))          # Выведем длительность обучения этой эпохи"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 27s 121ms/batch - batch_loss: 1.9272\n",
            "Эпоха 1 Ошибка 2.4461\n",
            "Время на 1 эпоху 27 сек\n",
            "125/125 [==============================] - 15s 121ms/batch - batch_loss: 1.4900\n",
            "Эпоха 2 Ошибка 1.6846\n",
            "Время на 1 эпоху 15 сек\n",
            "125/125 [==============================] - 15s 122ms/batch - batch_loss: 1.3640\n",
            "Эпоха 3 Ошибка 1.3813\n",
            "Время на 1 эпоху 15 сек\n",
            "125/125 [==============================] - 16s 124ms/batch - batch_loss: 1.0486\n",
            "Эпоха 4 Ошибка 1.1469\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 16s 125ms/batch - batch_loss: 0.8416\n",
            "Эпоха 5 Ошибка 0.9428\n",
            "Время на 1 эпоху 16 сек\n",
            "125/125 [==============================] - 16s 127ms/batch - batch_loss: 0.7352\n",
            "Эпоха 6 Ошибка 0.7552\n",
            "Время на 1 эпоху 16 сек\n",
            "125/125 [==============================] - 16s 128ms/batch - batch_loss: 0.5982\n",
            "Эпоха 7 Ошибка 0.5893\n",
            "Время на 1 эпоху 16 сек\n",
            "125/125 [==============================] - 16s 128ms/batch - batch_loss: 0.4578\n",
            "Эпоха 8 Ошибка 0.4502\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 16s 129ms/batch - batch_loss: 0.3499\n",
            "Эпоха 9 Ошибка 0.3409\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 16s 129ms/batch - batch_loss: 0.3012\n",
            "Эпоха 10 Ошибка 0.2582\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 16s 131ms/batch - batch_loss: 0.2329\n",
            "Эпоха 11 Ошибка 0.1962\n",
            "Время на 1 эпоху 16 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.1490\n",
            "Эпоха 12 Ошибка 0.1530\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 132ms/batch - batch_loss: 0.1520\n",
            "Эпоха 13 Ошибка 0.1230\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 16s 132ms/batch - batch_loss: 0.1033\n",
            "Эпоха 14 Ошибка 0.1037\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 16s 132ms/batch - batch_loss: 0.0929\n",
            "Эпоха 15 Ошибка 0.0883\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 133ms/batch - batch_loss: 0.0919\n",
            "Эпоха 16 Ошибка 0.0773\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0684\n",
            "Эпоха 17 Ошибка 0.0700\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 133ms/batch - batch_loss: 0.0777\n",
            "Эпоха 18 Ошибка 0.0650\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0731\n",
            "Эпоха 19 Ошибка 0.0603\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0679\n",
            "Эпоха 20 Ошибка 0.0582\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0648\n",
            "Эпоха 21 Ошибка 0.0553\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0653\n",
            "Эпоха 22 Ошибка 0.0540\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0443\n",
            "Эпоха 23 Ошибка 0.0537\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0525\n",
            "Эпоха 24 Ошибка 0.0536\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0722\n",
            "Эпоха 25 Ошибка 0.0528\n",
            "Время на 1 эпоху 17 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0562\n",
            "Эпоха 26 Ошибка 0.0511\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 134ms/batch - batch_loss: 0.0629\n",
            "Эпоха 27 Ошибка 0.0504\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0649\n",
            "Эпоха 28 Ошибка 0.0519\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0668\n",
            "Эпоха 29 Ошибка 0.0519\n",
            "Время на 1 эпоху 20 сек\n",
            "125/125 [==============================] - 17s 135ms/batch - batch_loss: 0.0667\n",
            "Эпоха 30 Ошибка 0.0549\n",
            "Время на 1 эпоху 17 сек\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzCVG3YhYj0O"
      },
      "source": [
        "Данная функция собирает модель кодера, декодера и attention для работы в режиме перевода (предсказания).\n",
        "\n",
        "На входе переводимое русское предложение, на выходе его английский перевод"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX4koS1irAnJ"
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # Создаем начальные настройки графика внимания\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) \n",
        "    \n",
        "    # Предобрабатываем предложение\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')]   # Преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')        # Делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs)                                          # Конвертируем в тф тензор\n",
        "\n",
        "    result = ''                                                                    # Сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]                                                # Задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)                                  # Передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden                                                        # Состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) # Передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ):                                               # Идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        # Результат конвертируем из индекса в слово и сохраняем в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # Педсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    # Вернем перевод, входную фразу и веса внимания\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP7AnPSBcC9D"
      },
      "source": [
        "Нам интересно как связаны слова в исходной фразе и в ее переведе. Функция отрисовывает веса внимания в виде 2D матрицы, соотносит каждую пару  слов  ее весом  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8ZVMbHrFYj"
      },
      "source": [
        "def plot_attention(attention,           # Веса внимания\n",
        "                   sentence,            # Исходная фраза\n",
        "                   predicted_sentence): # Предсказаные перевод\n",
        "  \n",
        "    fig = plt.figure(figsize=(10,10))                                   # Зададим размер \n",
        "    ax = fig.add_subplot(1, 1, 1)                                       # Добавим 1 картинку\n",
        "    ax.matshow(attention, cmap='viridis')                               # Нарисуем 2d матрицу\n",
        "    fontdict = {'fontsize': 14}                                         # Зададим размер надписей\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90) # Добавим надпись по горизонтальной оси\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)    # Добавим надпись по вертикальной оси\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))               # Зададим форматирование делений на осях графиков\n",
        "    plt.show()                                                          # Отрисуем изображение"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXrttZ_Ccd--"
      },
      "source": [
        "Соберем написанные ранее функции вместе. Будем переводить фразы и строить матрицы внимания(attention)  - смотреть связи слов в предложении"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7afFCab-N_Xf"
      },
      "source": [
        "Создадим функцию для перевода фраз с визуализацией матрицы внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8G96tWrHmn"
      },
      "source": [
        "def translate(sentence): # Функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)  # Отдадим фразу. Получим перевод, входную фразу,  веса внимания\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))          # Выведем входную фразу \n",
        "    print('Предсказанный перевод: {}'.format(result)) # Выведем полученный перевод\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))] # Возьмем весы внимания, только для слов во фразах. Хвосты не смотрим\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))              # Выведем веса внимания"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsbPAP5rJle",
        "outputId": "eb662434-13e9-43dc-8ff2-2f2d949d640c"
      },
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fef50df4190>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcH-0rkFPNeU"
      },
      "source": [
        "И, наконец, переведём предложение и выведем визуализацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "bBi0SqkJrMeK",
        "outputId": "51e443f6-478c-46d4-facd-787ca85c7476"
      },
      "source": [
        "translate('давайте дружить')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> давайте дружить <end>\n",
            "Предсказанный перевод: let s glad . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "X2VVb9LHrOv8",
        "outputId": "87e23b21-b9a9-48f1-e131-516f35609a54"
      },
      "source": [
        "translate('у тебя всё хорошо')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо <end>\n",
            "Предсказанный перевод: you re all you . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "uWC8-1DDrPQ1",
        "outputId": "93977791-ce11-424d-9d51-318293ffb621"
      },
      "source": [
        "translate('у тебя всё хорошо?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо ? <end>\n",
            "Предсказанный перевод: do you have it ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sahW4uQD51Rv"
      },
      "source": [
        "Что можно сказать. Как переводчик сеть не очень. Но связи слов в предложениях уже находит"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUboNys8E1AX"
      },
      "source": [
        "**Содержание темы**\n",
        "\n",
        "\n",
        "1. [Теория](https://colab.research.google.com/drive/1f2RV3yzZIqRoGpP9y-b45NgnivaIT-4q?usp=sharing)\n",
        "\n",
        "2. Практика\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}